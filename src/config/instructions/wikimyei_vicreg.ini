/*
  wikimyei_vicreg.ini
  ===================
  Purpose:
    Typed key-value profile for VICReg model/runtime settings used by wikimyei.
    Values are explicit and parsed as: key:type = value.

  Format:
    <key>:<type> = <value>   # optional inline comment
    Supported type examples used here:
      path, int, bool, str

  Key groups:
    - Artifact/runtime: model_path, verbose_train, device, dtype
    - Training budget placeholders: n_epochs, n_iters
      (wave orchestration remains the authoritative execution budget)
    - Model shape: encoding_dims, channel_expansion_dim, fused_feature_dim,
      encoder_hidden_dims, encoder_depth
    - Projector config: projector_mlp_spec, projector_norm, projector_activation,
      projector_hidden_bias, projector_last_bias, projector_bn_in_fp32
    - Optimizer/SWA policy: swa_start_iter, optimizer_threshold_reset,
      enable_buffer_averaging

  Semantics:
    - This file defines component-local VICReg runtime configuration.
    - Wave + jkimyei selection determine whether and how training is executed.
*/

# VICReg profile: key:type = value # optional comment
model_path:path = /tmp/vicreg.ckpt # Path to save/load the model
n_epochs:int = 500 # Total passes over dataset (-1 means loop forever)
n_iters:int = -1 # Hard cap on iterations (batches)
swa_start_iter:int = 1000 # Global iteration where SWA begins
verbose_train:bool = true # Print progress messages
encoding_dims:int = 72 # Encoder output embedding dimensions
channel_expansion_dim:int = 64 # Width multiplier for first conv block
fused_feature_dim:int = 32 # Channel count after fusion block
encoder_hidden_dims:int = 24 # Hidden width inside residual blocks
encoder_depth:int = 10 # Number of residual blocks
projector_mlp_spec:str = 128-256-128 # Projector layer widths
projector_norm:str = LayerNorm # BatchNorm1d | LayerNorm | None
projector_activation:str = SiLU # ReLU | SiLU
projector_hidden_bias:bool = false # Ignored when using BatchNorm1d
projector_last_bias:bool = false
projector_bn_in_fp32:bool = true # Used only with BatchNorm1d
optimizer_threshold_reset:int = 500 # AdamW pow reset step (-1 disables)
enable_buffer_averaging:bool = false # SWA buffer averaging policy
dtype:str = kFloat32 # torch dtype token
device:str = gpu # cpu | cuda:0 | gpu
