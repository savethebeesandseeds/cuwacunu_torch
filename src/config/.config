[GENERAL]
    # ───────────────────── GENERAL SETUP ────────────────────────────
    exchange_type           = TEST
    torch_seed              = 42
    absolute_base_symbol    = USDT
[DATA_LOADER]
    # ───────────────────── DATALOADER SETUP ────────────────────────────
    dataloader_batch_size       = 64      # mini-batch size B
    dataloader_workers          = 8       # background worker threads for data loading
    dataloader_force_binarization = true  # convert inputs to {0,1} (useful for images); false keeps floats
[VICReg]
    # ───────────────────── Files ──────────────────────────
    model_path                  = /tmp/vicreg.ckpt # Path to save/load the model
    # ───────────────────── TRAINING LOOP CONTROL ──────────────────────────
    n_epochs                    = 500     # total passes over the entire dataset (-1 means "loop forever")
    n_iters                     = -1      # hard cap on *iterations* (batches); -1 lets n_epochs decide
    swa_start_iter              = 1000    # global iteration at which Stochastic-Weight-Averaging begins
    verbose_train               = true    # print progress messages at the configured intervals
    # ───────────────────── ARCHITECTURE / REPRESENTATION SIZE ──────────────────
    encoding_dims               = 72      # dimensionality of the encoder’s output embedding  (Dx)
    channel_expansion_dim       = 64      # width multiplier for the first conv block (C → C×mult)
    fused_feature_dim           = 32      # channel count after the “fusion” block that merges temporal features
    encoder_hidden_dims         = 24      # hidden width inside each residual block
    encoder_depth               = 10      # number of residual blocks stacked in the encoder
    projector_mlp_spec          = 128-256-128  # layer widths of the projector: 72 -> 128 -> 256 -> 128
    projector_norm              = LayerNorm      # {BatchNorm1d, LayerNorm, None}
    projector_activation        = SiLU           # {ReLU, SiLU}
    projector_hidden_bias       = false          # {true,false}; ignored if projector_norm=BatchNorm1d
    projector_last_bias         = false          # {true,false}
    projector_bn_in_fp32        = true           # {true,false}; used only if projector_norm=BatchNorm1d
    # ───────────────────── EXECUTION POLICY ───────────────
    optimizer_threshold_reset   = 500     # Step where to reset AdamW pow exponent. -1 for non reset
    enable_buffer_averaging     = false   # if true, average BatchNorm running stats in SWA; false copies stats verbatim from the live encoder
    dtype                       = kFloat32  # tensor precision (kFloat32, kFloat16, kBFloat16, …)
    device                      = gpu       # ‘cpu’, ‘cuda:0’, ‘gpu’, etc.
[VALUE_ESTIMATION]
    # ───────────────────── Files ──────────────────────────
    model_path                  = /tmp/value_estimation.ckpt # Path to save/load the model
    # ───────────────────── TRAINING LOOP CONTROL ──────────────────────────
    n_epochs                    = 500       # total passes over the entire dataset (-1 means "loop forever")
    n_iters                     = -1        # hard cap on *iterations* (batches); -1 lets n_epochs decide
    verbose_train               = true      # print progress messages at the configured intervals
    telemetry_every             = -1        # during training, how often to print telemetry (-1 means never)
    # ───────────────────── Architecture ────────────────────────────────
    target_dims                 = 3         # dimensions to track from e.g. in case of dkline, 0 == open_price, 3 == close_price  (view ::tensor_features() in exchange_types_data.cpp)
    target_weights              = 0.5       # weights of training importance for the target_dims. 
    mixture_comps               = 10        # 
    features_hidden             = 12        # 
    residual_depth              = 3         # 
    grad_clip                   = 1.0       # value to clip the gradients with
    optimizer_threshold_reset   = 500       # Step where to reset AdamW pow exponent. -1 for non reset
    # ───────────────────── RUNTIME SETTINGS ────────────────────────────
    dtype                       = kFloat32  # tensor precision (kFloat32, kFloat16, kBFloat16, …)
    device                      = gpu       # ‘cpu’, ‘cuda:0’, ‘gpu’, etc.
[REAL_EXCHANGE]
    AES_salt                = /cuwacunu/src/config/aes_salt.enc
    Ed25519_pkey            = /cuwacunu/src/config/ed25519key.pem
    EXCHANGE_api_filename   = /cuwacunu/src/config/exchange.key
    websocket_url           = wss://ws-api.binance.com:443/ws-api/v3
[TEST_EXCHANGE]
    AES_salt                = /cuwacunu/src/config/test_aes_salt.enc
    Ed25519_pkey            = /cuwacunu/src/config/test_ed25519key.pem
    EXCHANGE_api_filename   = /cuwacunu/src/config/test_exchange.key
    websocket_url           = wss://testnet.binance.vision/ws-api/v3
[BNF]
    observation_pipeline_bnf_filename           = /cuwacunu/src/config/observation_pipeline.bnf
    observation_pipeline_instruction_filename   = /cuwacunu/src/config/observation_pipeline.instruction
    training_components_bnf_filename              = /cuwacunu/src/config/training_components.bnf
    training_components_instruction_filename      = /cuwacunu/src/config/training_components.instruction